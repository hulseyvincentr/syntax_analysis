# organize_metadata_excel.pyfrom __future__ import annotationsfrom pathlib import Pathfrom typing import List, Optional, Union, Dict, Any, Tupleimport jsonimport pandas as pddef load_metadata_with_schema(    excel_path: Union[str, Path],    *,    sheet_name: Union[str, int] = 0,    id_col: str = "Animal ID",    animal_level_cols: Optional[List[str]] = None,     # e.g. ["Treatment date", "Treatment type"]    injection_level_cols: Optional[List[str]] = None,  # e.g. ["Target region", "AP (mm)", ...]) -> Dict[str, Dict[str, Any]]:    """    Read an Excel sheet and organize it into a metadata dict per Animal ID.    Parameters    ----------    excel_path : str or Path        Path to the Excel file.    sheet_name : str or int, default 0        Sheet name or index.    id_col : str, default "Animal ID"        Column used to group rows by animal.    animal_level_cols : list[str] or None        Columns that should be stored once per animal (same for all injections).        If None, these will be inferred automatically.    injection_level_cols : list[str] or None        Columns that should be stored for each injection.        If None, these will be all remaining non-animal-level columns.    Returns    -------    metadata : dict        {          "USA5288": {              "Animal ID": "USA5288",              # animal-level fields...              "Treatment date": ...,              "Treatment type": ...,              ...              "injections": [                  {  # injection-level fields...                    "Hemisphere": "L",                    "Target region": "...",                    "AP (mm)": 5.6,                    ...                  },                  ...              ],          },          ...        }    """    excel_path = Path(excel_path)    df = pd.read_excel(excel_path, sheet_name=sheet_name)    # --- Clean up the user-specified column lists (drop missing / id_col) ---    all_cols = set(df.columns)    if animal_level_cols is not None:        animal_level_cols = [c for c in animal_level_cols if c in all_cols and c != id_col]    if injection_level_cols is not None:        injection_level_cols = [c for c in injection_level_cols if c in all_cols and c != id_col]    # --- If animal_level_cols not given, infer them as "constant per animal" ---    if animal_level_cols is None:        inferred: List[str] = []        for col in df.columns:            if col == id_col:                continue            # If every animal has only one unique value in this column,            # we'll treat it as animal-level.            if df.groupby(id_col)[col].nunique(dropna=True).max() <= 1:                inferred.append(col)        animal_level_cols = inferred    # --- If injection_level_cols not given, use the remaining columns ---    if injection_level_cols is None:        injection_level_cols = [c for c in df.columns if c not in animal_level_cols and c != id_col]    metadata: Dict[str, Dict[str, Any]] = {}    for animal_id, group in df.groupby(id_col):        # animal-level: just take the first non-null value for each column        animal_entry: Dict[str, Any] = {id_col: animal_id}        for col in animal_level_cols:            vals = group[col].dropna().unique()            animal_entry[col] = vals[0] if len(vals) > 0 else None        # injection-level: one dict per row        injections = group[injection_level_cols].to_dict(orient="records")        animal_entry["injections"] = injections        metadata[str(animal_id)] = animal_entry    return metadata# ──────────────────────────────────────────────────────────────────────────────# Helpers for attaching lesion-volume JSONs# ──────────────────────────────────────────────────────────────────────────────def _normalize_hemisphere_token(token: str) -> Optional[str]:    """    Map a token like 'left', 'right', 'L', 'R' to 'L' or 'R'.    Returns    -------    'L', 'R', or None if the token doesn't look like a hemisphere label.    """    t = token.strip().lower()    if not t:        return None    if t in {"l", "left"}:        return "L"    if t in {"r", "right"}:        return "R"    return Nonedef _parse_animal_and_hemi_from_filename(    path: Union[str, Path],) -> Tuple[Optional[str], Optional[str]]:    """    Infer animal_id and hemisphere from a final-volumes JSON filename.    Assumes patterns like:        R08_left_hemisphere_Lesion_Area_converted_for_validation_final_volumes.json        USA5288_right_042624.01_final_volumes.json    We treat:        - the first '_'-separated token as the animal_id        - any later token that looks like 'left'/'right'/'L'/'R' as the hemisphere.    """    p = Path(path)    stem = p.stem    parts = stem.split("_")    if not parts:        return None, None    animal_id = parts[0]    hemi: Optional[str] = None    for part in parts[1:]:        hemi_candidate = _normalize_hemisphere_token(part)        if hemi_candidate is not None:            hemi = hemi_candidate            break    return animal_id, hemidef _attach_volume_jsons(    metadata: Dict[str, Dict[str, Any]],    volumes_dir: Union[str, Path],    *,    pattern: str = "*_final_volumes.json",) -> None:    """    Look in `volumes_dir` for JSON files like '*_final_volumes.json',    infer (animal_id, hemisphere) from the filename, and attach the    volume metrics to the corresponding animal entry in `metadata`.    The JSON is stored in:        entry["lesion_volumes_by_hemisphere"][hemi] = vol_data    and each key is also flattened into a column-friendly field with    a hemisphere prefix, e.g.:        "Percent of Area X Lesioned (%)"  (hemi='L')        → "L_Percent_of_Area_X_Lesioned_pct"    so that turning the metadata dict into a DataFrame yields one column    per metric per hemisphere.    """    base = Path(volumes_dir)    if not base.is_dir():        print(f"[WARN] volumes_dir={base} is not a directory; skipping volume JSONs.")        return    json_paths = sorted(base.glob(pattern))    if not json_paths:        print(f"[INFO] No files matching {pattern!r} found in {base}")        return    for fpath in json_paths:        animal_id, hemi = _parse_animal_and_hemi_from_filename(fpath)        if animal_id is None or hemi is None:            print(f"[WARN] Could not infer animal_id/hemisphere from {fpath.name}; skipping.")            continue        animal_key = str(animal_id)        if animal_key not in metadata:            print(                f"[WARN] Volume JSON {fpath.name} refers to animal {animal_key}, "                "which is not present in metadata; skipping."            )            continue        try:            with fpath.open("r") as fh:                vol_data = json.load(fh)        except Exception as exc:            print(f"[WARN] Failed to read {fpath}: {exc}; skipping.")            continue        entry = metadata[animal_key]        # Keep a nested dict of all raw volume JSONs        volumes_by_hemi = entry.setdefault("lesion_volumes_by_hemisphere", {})        volumes_by_hemi[hemi] = vol_data        # Flatten keys into hemisphere-prefixed columns        for raw_key, value in vol_data.items():            safe = str(raw_key)            # Make column-friendly:            safe = safe.replace("%", "pct")            safe = safe.replace("µ", "u")            safe = safe.replace("(", "").replace(")", "")            safe = safe.replace("/", "_per_")            safe = "_".join(safe.split())  # spaces → underscores            colname = f"{hemi}_{safe}"            if colname in entry:                print(                    f"[WARN] Overwriting existing field {colname!r} for animal "                    f"{animal_key!r} from {fpath.name}"                )            entry[colname] = value# ──────────────────────────────────────────────────────────────────────────────# Area X–specific metadata wrapper# ──────────────────────────────────────────────────────────────────────────────def build_areax_metadata(    excel_file: Union[str, Path],    *,    sheet_name: Union[str, int] = 0,    volumes_dir: Optional[Union[str, Path]] = None,) -> Dict[str, Dict[str, Any]]:    """    Convenience wrapper for your Area X lesion metadata sheet.    Uses fixed animal-level and injection-level columns that match your schema.    In addition to the base metadata, this function adds several derived    animal-level fields per animal:        - "Medial Area X hit type"        - "Lateral Area X hit type"        - "Lesion hit type"   (overall per-animal label; useful for plotting)        - "total_inj_volume"  (sum of "Injection volume (nL)" across ALL          injections and BOTH hemispheres, in nL)    Optionally, if `volumes_dir` is provided and contains files matching    '*_final_volumes.json', each JSON is matched to an (animal, hemisphere)    based on the filename and its lesion-volume metrics are attached to    that animal's entry (nested + flattened into L_* / R_* keys).    Region hit-type values (per medial/lateral) are:        - "bilateral"      → both L and R hemispheres have ≥1 hit (Y)        - "unilateral_L"   → only left hemisphere has hits        - "unilateral_R"   → only right hemisphere has hits        - "miss"           → saw explicit N(s) but no Y in either hemisphere        - "unknown"        → no usable Y/N info or ambiguous case    Overall "Lesion hit type" values:        - "sham saline injection"        - "large lesion Area X not visible"        - "Area X visible (single hit)"        - "Area X visible (medial+lateral hit)"        - "miss"        - "unknown"        - "lesion hit (visibility unknown)"    """    excel_file = Path(excel_file)    animal_level_cols = [        "Treatment date",        "Treatment type",        "centage of Area X volume lesion",  # match your exact Excel header if present        "Medial Area X hit?",        "Lateral Area X hit?",        "Spillover above lamina?",        "Area X visible in histology?",    ]    # IMPORTANT: include hit columns in injection_level_cols as well so each    # injection dict keeps its own per-row hit flags.    injection_level_cols = [        "Hemisphere",        "Target region",        "Head angle injection #",        "AP (mm)",        "ML (mm)",        "DV (mm)",        "Injection volume (nL)",        "Injection rate (nL/s)",        "Medial Area X hit?",        "Lateral Area X hit?",    ]    metadata = load_metadata_with_schema(        excel_file,        sheet_name=sheet_name,        id_col="Animal ID",        animal_level_cols=animal_level_cols,        injection_level_cols=injection_level_cols,    )    # Optionally attach lesion-volume JSONs (e.g. *_final_volumes.json)    if volumes_dir is not None:        _attach_volume_jsons(metadata, volumes_dir)    # ---- helpers for hit-type classification ----    def _normalize_flag(val: Any) -> Optional[bool]:        """Return True/False for Y/N-like values; None if unknown/blank.        Robust to strings like 'N (sham lesion)' by looking at the first character.        """        if val is None:            return None        s = str(val).strip()        if not s:            return None        su = s.upper()        # Accept strings that start with Y/N (e.g., "N (...)" or "Y (...)")        if su[0] == "Y":            return True        if su[0] == "N":            return False        # Fallback exact matches        if su in {"YES", "TRUE", "1", "T"}:            return True        if su in {"NO", "FALSE", "0", "F"}:            return False        return None    def _parse_visible_flag(val: Any) -> Optional[bool]:        """        Parse 'Area X visible in histology?'.        Returns        -------        True  → clearly visible (starts with 'Y', e.g. 'Yes')        False → clearly not visible (starts with 'N', e.g. 'No', 'Not visible', 'N (...)')        None  → unknown/ambiguous        """        if val is None:            return None        s = str(val).strip()        if not s:            return None        su = s.upper()        if su[0] == "Y":            return True        if su[0] == "N":            return False        return None    def _classify_hit_type(        entry: Dict[str, Any],        *,        hit_key: str,        target_keyword: str,    ) -> str:        """        Classify hit type for one region (medial / lateral) based on per-row injection information.        Returns one of:            "bilateral", "unilateral_L", "unilateral_R", "miss", "unknown"        """        injections = entry.get("injections", []) or []        hemi_with_hit = set()  # hemispheres with at least one Y        hemi_with_any = set()  # hemispheres with any Y/N info        for inj in injections:            region = str(inj.get("Target region", "")).strip().lower()            hemi = str(inj.get("Hemisphere", "")).strip().upper()            # Be permissive: if region doesn’t contain the target keyword,            # but still mentions "area x", include it.            if target_keyword.lower() not in region and "area x" not in region:                continue            flag = _normalize_flag(inj.get(hit_key))            if flag is None or hemi not in {"L", "R"}:                continue            hemi_with_any.add(hemi)            if flag:                hemi_with_hit.add(hemi)        # --- classification logic ---        if not hemi_with_any:            # No explicit Y/N info for either hemisphere            return "unknown"        if not hemi_with_hit:            # We saw only N’s (no Y’s) → miss            return "miss"        if hemi_with_hit == {"L", "R"}:            return "bilateral"        if hemi_with_hit == {"L"}:            return "unilateral_L"        if hemi_with_hit == {"R"}:            return "unilateral_R"        # fallback        return "unknown"    def _has_hit(region_type: str) -> bool:        return region_type in {"bilateral", "unilateral_L", "unilateral_R"}    def _compute_overall_lesion_hit_type(        *,        treatment_type: str,        ax_visible_flag: Optional[bool],        medial_type: str,        lateral_type: str,    ) -> str:        """Compute a single per-animal lesion hit type label used for plotting."""        t = (treatment_type or "").strip().lower()        # Sham override        if "saline" in t and "sham" in t:            return "sham saline injection"        # NMA + not visible override        is_nma_lesion = ("nma" in t) and ("lesion" in t)        if is_nma_lesion and ax_visible_flag is False:            return "large lesion Area X not visible"        medial_hit = _has_hit(medial_type)        lateral_hit = _has_hit(lateral_type)        hit_score = int(medial_hit) + int(lateral_hit)        if hit_score == 0:            # If we saw explicit misses, call miss; else unknown            if medial_type == "miss" or lateral_type == "miss":                return "miss"            return "unknown"        # If explicitly not visible (even outside NMA), respect it        if ax_visible_flag is False:            return "large lesion Area X not visible"        if ax_visible_flag is True:            return "Area X visible (medial+lateral hit)" if hit_score >= 2 else "Area X visible (single hit)"        return "lesion hit (visibility unknown)"    # ---- per-animal derived fields: total_inj_volume + hit types ----    for animal_id, entry in metadata.items():        injections = entry.get("injections", []) or []        # 1) Sum total injection volume across BOTH hemispheres & ALL injections        total_vol = 0.0        for inj in injections:            vol = inj.get("Injection volume (nL)")            if vol is None:                continue            # handle numbers or numeric-like strings, ignore non-numeric            try:                v = float(vol)            except Exception:                # If it's something like NaN (from pandas), skip it                try:                    if pd.isna(vol):                        continue                except Exception:                    pass                continue            total_vol += v        entry["total_inj_volume"] = total_vol        # Normalize treatment type + visibility        ttype_raw = entry.get("Treatment type", "")        ttype = str(ttype_raw).strip().lower()        ax_visible_flag = _parse_visible_flag(entry.get("Area X visible in histology?"))        # 2a) Saline sham injections → override all hit types        if "saline" in ttype and "sham" in ttype:            label = "sham saline injection"            entry["Medial Area X hit type"] = label            entry["Lateral Area X hit type"] = label            entry["Lesion hit type"] = label            continue        # 2b) NMA lesions: if Area X not visible, override classification        is_nma_lesion = ("nma" in ttype) and ("lesion" in ttype)        if is_nma_lesion and ax_visible_flag is False:            label = "large lesion Area X not visible"            entry["Medial Area X hit type"] = label            entry["Lateral Area X hit type"] = label            entry["Lesion hit type"] = label            continue        # 2c) Otherwise: bilateral/unilateral/miss/unknown logic based on Y/N flags.        med_type = _classify_hit_type(            entry,            hit_key="Medial Area X hit?",            target_keyword="Medial Area X",        )        lat_type = _classify_hit_type(            entry,            hit_key="Lateral Area X hit?",            target_keyword="Lateral Area X",        )        entry["Medial Area X hit type"] = med_type        entry["Lateral Area X hit type"] = lat_type        # Overall per-animal label        entry["Lesion hit type"] = _compute_overall_lesion_hit_type(            treatment_type=entry.get("Treatment type", ""),            ax_visible_flag=ax_visible_flag,            medial_type=med_type,            lateral_type=lat_type,        )    return metadatadef save_metadata_excel_with_hit_type_sheet(    excel_file: Union[str, Path],    *,    sheet_name: Union[str, int] = 0,    volumes_dir: Optional[Union[str, Path]] = None,    out_excel: Optional[Union[str, Path]] = None,    out_sheet_name: str = "metadata_with_hit_type",    add_animal_summary_sheet: bool = True,    animal_summary_sheet_name: str = "animal_hit_type_summary",) -> Path:    """    Create a NEW Excel workbook that contains:      - the original metadata sheet (copied)      - a new sheet with added columns:           'Lesion hit type', 'Medial Area X hit type', 'Lateral Area X hit type'      - optional per-animal summary sheet    Parameters    ----------    excel_file : str or Path        Path to the Area X metadata Excel workbook.    sheet_name : str or int, default 0        Sheet name or index to read from excel_file.    volumes_dir : str or Path, optional        If provided, attaches *_final_volumes.json metrics via build_areax_metadata.    out_excel : str or Path, optional        Output path for the NEW workbook. If None, appends "_with_hit_types.xlsx".    out_sheet_name : str, default "metadata_with_hit_type"        Name of the new sheet that includes hit-type columns.    add_animal_summary_sheet : bool, default True        If True, adds a sheet with one row per animal (summary).    animal_summary_sheet_name : str, default "animal_hit_type_summary"        Name of the per-animal summary sheet.    Returns    -------    Path to the saved workbook.    """    excel_file = Path(excel_file)    # Resolve original sheet name if an integer was provided    xl = pd.ExcelFile(excel_file)    orig_sheet = xl.sheet_names[sheet_name] if isinstance(sheet_name, int) else sheet_name    # Compute per-animal metadata (includes derived hit-type fields)    meta = build_areax_metadata(        excel_file,        sheet_name=orig_sheet,        volumes_dir=volumes_dir,    )    # Build per-animal maps for columns we want to attach back onto the row-level sheet    hit_map = {aid: d.get("Lesion hit type", "unknown") for aid, d in meta.items()}    med_map = {aid: d.get("Medial Area X hit type", "unknown") for aid, d in meta.items()}    lat_map = {aid: d.get("Lateral Area X hit type", "unknown") for aid, d in meta.items()}    # Read original sheet and add columns    df = pd.read_excel(excel_file, sheet_name=orig_sheet)    if "Animal ID" not in df.columns:        raise ValueError("Expected 'Animal ID' column in the metadata sheet.")    key = df["Animal ID"].astype(str).str.strip()    df2 = df.copy()    df2["Lesion hit type"] = key.map(hit_map)    df2["Medial Area X hit type"] = key.map(med_map)    df2["Lateral Area X hit type"] = key.map(lat_map)    # Output file path    if out_excel is None:        out_excel = excel_file.with_name(excel_file.stem + "_with_hit_types.xlsx")    out_excel = Path(out_excel)    # Write workbook with multiple sheets    with pd.ExcelWriter(out_excel, engine="openpyxl") as writer:        df.to_excel(writer, sheet_name=str(orig_sheet), index=False)        df2.to_excel(writer, sheet_name=out_sheet_name, index=False)        if add_animal_summary_sheet:            animal_df = pd.DataFrame.from_dict(meta, orient="index").reset_index(drop=True)            preferred = [                "Animal ID",                "Treatment type",                "Area X visible in histology?",                "Lesion hit type",                "Medial Area X hit type",                "Lateral Area X hit type",                "total_inj_volume",            ]            cols = [c for c in preferred if c in animal_df.columns]            if cols:                animal_df[cols].to_excel(writer, sheet_name=animal_summary_sheet_name, index=False)            else:                animal_df.to_excel(writer, sheet_name=animal_summary_sheet_name, index=False)    return out_excel"""Example usage-------------from pathlib import Pathfrom pprint import pprintimport pandas as pdfrom organize_metadata_excel import build_areax_metadata, save_metadata_excel_with_hit_type_sheet# Path to histology directory where your *_final_volumes.json livehistology_volumes_dir = Path(    "/Volumes/my_own_ssd/2024_2025_Area_X_analysis/lesion_quantification_csvs_jsons")# Path to your Excel sheetexcel_file = Path(    "/Volumes/my_own_ssd/2024_2025_Area_X_analysis/Area_X_lesion_metadata.xlsx")# Build the per-animal metadata dictionary, including lesion-volume JSONs (optional)metadata = build_areax_metadata(    excel_file,    sheet_name=0,    volumes_dir=histology_volumes_dir,   # optional)# Inspect one animal entry (replace "R10" with a real Animal ID from your sheet)pprint(metadata["R10"])# Convert the metadata dict into a DataFrame (one row per animal)organized_metadata = pd.DataFrame.from_dict(metadata, orient="index")# Check the available columns, including the derived fieldsprint(organized_metadata.columns)print(organized_metadata.head())# Save a new workbook with an extra sheet that includes "Lesion hit type" as a columnout_path = save_metadata_excel_with_hit_type_sheet(    excel_file,    sheet_name=0,    volumes_dir=histology_volumes_dir,   # optional)print("Saved:", out_path)"""