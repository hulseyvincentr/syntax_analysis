# organize_metadata_excel.pyfrom pathlib import Pathfrom typing import List, Optional, Union, Dict, Any, Tupleimport jsonimport pandas as pddef load_metadata_with_schema(    excel_path: Union[str, Path],    *,    sheet_name: Union[str, int] = 0,    id_col: str = "Animal ID",    animal_level_cols: Optional[List[str]] = None,     # e.g. ["Treatment date", "Treatment type"]    injection_level_cols: Optional[List[str]] = None,  # e.g. ["Target region", "AP (mm)", ...]) -> Dict[str, Dict[str, Any]]:    """    Read an Excel sheet and organize it into a metadata dict per Animal ID.    Parameters    ----------    excel_path : str or Path        Path to the Excel file.    sheet_name : str or int, default 0        Sheet name or index.    id_col : str, default "Animal ID"        Column used to group rows by animal.    animal_level_cols : list[str] or None        Columns that should be stored once per animal (same for all injections).        If None, these will be inferred automatically.    injection_level_cols : list[str] or None        Columns that should be stored for each injection.        If None, these will be all remaining non-animal-level columns.    Returns    -------    metadata : dict        {          "USA5288": {              "Animal ID": "USA5288",              # animal-level fields...              "Treatment date": ...,              "Treatment type": ...,              ...              "injections": [                  {  # injection-level fields...                    "Hemisphere": "L",                    "Target region": "...",                    "AP (mm)": 5.6,                    ...                  },                  ...              ],          },          ...        }    """    excel_path = Path(excel_path)    df = pd.read_excel(excel_path, sheet_name=sheet_name)    # --- Clean up the user-specified column lists (drop missing / id_col) ---    all_cols = set(df.columns)    if animal_level_cols is not None:        animal_level_cols = [            c for c in animal_level_cols            if c in all_cols and c != id_col        ]    if injection_level_cols is not None:        injection_level_cols = [            c for c in injection_level_cols            if c in all_cols and c != id_col        ]    # --- If animal_level_cols not given, infer them as "constant per animal" ---    if animal_level_cols is None:        inferred: List[str] = []        for col in df.columns:            if col == id_col:                continue            # if every animal has only one unique value in this column,            # we'll treat it as animal-level            if df.groupby(id_col)[col].nunique(dropna=True).max() <= 1:                inferred.append(col)        animal_level_cols = inferred    # --- If injection_level_cols not given, use the remaining columns ---    if injection_level_cols is None:        injection_level_cols = [            c for c in df.columns            if c not in animal_level_cols and c != id_col        ]    metadata: Dict[str, Dict[str, Any]] = {}    for animal_id, group in df.groupby(id_col):        # animal-level: just take the first non-null value for each column        animal_entry: Dict[str, Any] = {id_col: animal_id}        for col in animal_level_cols:            vals = group[col].dropna().unique()            animal_entry[col] = vals[0] if len(vals) > 0 else None        # injection-level: one dict per row        injections = group[injection_level_cols].to_dict(orient="records")        animal_entry["injections"] = injections        metadata[str(animal_id)] = animal_entry    return metadata# ──────────────────────────────────────────────────────────────────────────────# Helpers for attaching lesion-volume JSONs# ──────────────────────────────────────────────────────────────────────────────def _normalize_hemisphere_token(token: str) -> Optional[str]:    """    Map a token like 'left', 'right', 'L', 'R' to 'L' or 'R'.    Returns    -------    'L', 'R', or None if the token doesn't look like a hemisphere label.    """    t = token.strip().lower()    if not t:        return None    if t in {"l", "left"}:        return "L"    if t in {"r", "right"}:        return "R"    return Nonedef _parse_animal_and_hemi_from_filename(    path: Union[str, Path],) -> Tuple[Optional[str], Optional[str]]:    """    Infer animal_id and hemisphere from a final-volumes JSON filename.    Assumes patterns like:        R08_left_hemisphere_Lesion_Area_converted_for_validation_final_volumes.json        USA5288_right_042624.01_final_volumes.json    We treat:        - the first '_'-separated token as the animal_id        - any later token that looks like 'left'/'right'/'L'/'R' as the hemisphere.    """    p = Path(path)    stem = p.stem    parts = stem.split("_")    if not parts:        return None, None    animal_id = parts[0]    hemi: Optional[str] = None    for part in parts[1:]:        hemi_candidate = _normalize_hemisphere_token(part)        if hemi_candidate is not None:            hemi = hemi_candidate            break    return animal_id, hemidef _attach_volume_jsons(    metadata: Dict[str, Dict[str, Any]],    volumes_dir: Union[str, Path],    *,    pattern: str = "*_final_volumes.json",) -> None:    """    Look in `volumes_dir` for JSON files like '*_final_volumes.json',    infer (animal_id, hemisphere) from the filename, and attach the    volume metrics to the corresponding animal entry in `metadata`.    The JSON is stored in:        entry["lesion_volumes_by_hemisphere"][hemi] = vol_data    and each key is also flattened into a column-friendly field with    a hemisphere prefix, e.g.:        "Percent of Area X Lesioned (%)"  (hemi='L')        → "L_Percent_of_Area_X_Lesioned_pct"    so that turning the metadata dict into a DataFrame yields one column    per metric per hemisphere.    """    base = Path(volumes_dir)    if not base.is_dir():        print(f"[WARN] volumes_dir={base} is not a directory; skipping volume JSONs.")        return    json_paths = sorted(base.glob(pattern))    if not json_paths:        print(f"[INFO] No files matching {pattern!r} found in {base}")        return    for fpath in json_paths:        animal_id, hemi = _parse_animal_and_hemi_from_filename(fpath)        if animal_id is None or hemi is None:            print(f"[WARN] Could not infer animal_id/hemisphere from {fpath.name}; skipping.")            continue        animal_key = str(animal_id)        if animal_key not in metadata:            print(                f"[WARN] Volume JSON {fpath.name} refers to animal {animal_key}, "                "which is not present in metadata; skipping."            )            continue        try:            with fpath.open("r") as fh:                vol_data = json.load(fh)        except Exception as exc:            print(f"[WARN] Failed to read {fpath}: {exc}; skipping.")            continue        entry = metadata[animal_key]        # Keep a nested dict of all raw volume JSONs        volumes_by_hemi = entry.setdefault("lesion_volumes_by_hemisphere", {})        volumes_by_hemi[hemi] = vol_data        # Flatten keys into hemisphere-prefixed columns        for raw_key, value in vol_data.items():            safe = str(raw_key)            # Make column-friendly:            safe = safe.replace("%", "pct")            safe = safe.replace("µ", "u")            safe = safe.replace("(", "").replace(")", "")            safe = safe.replace("/", "_per_")            safe = "_".join(safe.split())  # spaces → underscores            colname = f"{hemi}_{safe}"            if colname in entry:                print(                    f"[WARN] Overwriting existing field {colname!r} for animal "                    f"{animal_key!r} from {fpath.name}"                )            entry[colname] = value# ──────────────────────────────────────────────────────────────────────────────# Area X–specific metadata wrapper# ──────────────────────────────────────────────────────────────────────────────def build_areax_metadata(    excel_file: Union[str, Path],    *,    sheet_name: Union[str, int] = 0,    volumes_dir: Optional[Union[str, Path]] = None,) -> Dict[str, Dict[str, Any]]:    """    Convenience wrapper for your Area X lesion metadata sheet.    Uses fixed animal-level and injection-level columns that match your schema.    In addition to the base metadata, this function adds several derived    animal-level fields per animal:        - "Medial Area X hit type"        - "Lateral Area X hit type"        - "total_inj_volume" (sum of "Injection volume (nL)" across ALL          injections and BOTH hemispheres, in nL)    Optionally, if `volumes_dir` is provided and contains files matching    '*_final_volumes.json', each JSON is matched to an (animal, hemisphere)    based on the filename and its lesion-volume metrics are attached to    that animal's entry.    For each metric key in the JSON (e.g.        "Percent of Area X Lesioned (%)",        "Total Volume of Area X (um^3)",        ...    ), the function will create hemisphere-prefixed columns such as:        "L_Percent_of_Area_X_Lesioned_pct"        "R_Total_Volume_of_Area_X_um^3"        ...    Hit-type values can be:        - "bilateral"                    → both L and R hemispheres have ≥1 hit (Y)        - "unilateral_L"                 → only left hemisphere has hits        - "unilateral_R"                 → only right hemisphere has hits        - "miss"                         → at least one explicit N, but no Y in either hemisphere        - "sham saline injection"        → treatment is a saline sham injection        - "large lesion, Area X not visible"                                         → treatment is an NMA lesion and "Area X visible in histology?"                                           indicates not visible (starts with 'N')        - "unknown"                      → no usable Y/N information or ambiguous case    """    excel_file = Path(excel_file)    animal_level_cols = [        "Treatment date",        "Treatment type",        "centage of Area X volume lesion",  # match your exact Excel header        "Medial Area X hit?",        "Lateral Area X hit?",        "Spillover above lamina?",        "Area X visible in histology?",    ]    # IMPORTANT: include hit columns in injection_level_cols as well so each    # injection dict keeps its own per-row hit flags.    injection_level_cols = [        "Hemisphere",        "Target region",        "Head angle injection #",        "AP (mm)",        "ML (mm)",        "DV (mm)",        "Injection volume (nL)",        "Injection rate (nL/s)",        "Medial Area X hit?",        "Lateral Area X hit?",    ]    metadata = load_metadata_with_schema(        excel_file,        sheet_name=sheet_name,        id_col="Animal ID",        animal_level_cols=animal_level_cols,        injection_level_cols=injection_level_cols,    )    # Optionally attach lesion-volume JSONs (e.g. *_final_volumes.json)    if volumes_dir is not None:        _attach_volume_jsons(metadata, volumes_dir)    # ---- helpers for hit-type classification ----    def _normalize_flag(val: Any) -> Optional[bool]:        """Return True/False for Y/N-like values; None if unknown/blank."""        if val is None:            return None        s = str(val).strip().upper()        if not s:            return None        if s in {"Y", "YES", "TRUE", "1"}:            return True        if s in {"N", "NO", "FALSE", "0"}:            return False        return None    def _parse_visible_flag(val: Any) -> Optional[bool]:        """        Parse 'Area X visible in histology?'.        Returns        -------        True  → clearly visible (starts with 'Y', e.g. 'Yes')        False → clearly not visible (starts with 'N', e.g. 'No', 'Not visible')        None  → unknown/ambiguous        """        if val is None:            return None        s = str(val).strip()        if not s:            return None        s_upper = s.upper()        # Simple "starts with Y/N" check (handles 'Yes', 'No', 'Not visible', etc.)        if s_upper[0] == "Y":            return True        if s_upper[0] == "N":            return False        # Fallback to generic Y/N parser if it happens to match        return _normalize_flag(s)    def _classify_hit_type(        entry: Dict[str, Any],        *,        hit_key: str,        target_keyword: str,    ) -> str:        """        Classify hit type for one region (medial / lateral) based on per-row injection information.        Returns one of:            "bilateral", "unilateral_L", "unilateral_R", "miss", "unknown"        """        injections = entry.get("injections", []) or []        hemi_with_hit = set()  # hemispheres with at least one Y        hemi_with_any = set()  # hemispheres with any Y/N info        for inj in injections:            region = str(inj.get("Target region", "")).strip().lower()            hemi = str(inj.get("Hemisphere", "")).strip().upper()            # Be more permissive: if region doesn’t contain the target keyword,            # but still mentions "area x", we include it.            if target_keyword.lower() not in region and "area x" not in region:                continue            flag = _normalize_flag(inj.get(hit_key))            if flag is None or hemi not in {"L", "R"}:                continue            hemi_with_any.add(hemi)            if flag:                hemi_with_hit.add(hemi)        # --- classification logic ---        if not hemi_with_any:            # No explicit Y/N info for either hemisphere            return "unknown"        if not hemi_with_hit:            # We saw only N’s (no Y’s) → miss            return "miss"        if hemi_with_hit == {"L", "R"}:            return "bilateral"        if hemi_with_hit == {"L"}:            return "unilateral_L"        if hemi_with_hit == {"R"}:            return "unilateral_R"        # fallback        return "unknown"    # ---- per-animal derived fields: total_inj_volume + hit types ----    for animal_id, entry in metadata.items():        injections = entry.get("injections", []) or []        # 1) Sum total injection volume across BOTH hemispheres & ALL injections        total_vol = 0.0        for inj in injections:            vol = inj.get("Injection volume (nL)")            if vol is None:                continue            # handle numbers or numeric-like strings, ignore non-numeric            try:                v = float(vol)            except Exception:                # If it's something like NaN (from pandas), skip it                try:                    if pd.isna(vol):                        continue                except Exception:                    pass                continue            total_vol += v        # Store as animal-level field (in nL)        entry["total_inj_volume"] = total_vol        # 2) New hit-type classification logic        # Normalize treatment type        ttype_raw = entry.get("Treatment type", "")        ttype = str(ttype_raw).strip().lower()        # Parse "Area X visible in histology?"        ax_visible_flag = _parse_visible_flag(            entry.get("Area X visible in histology?")        )        # 2a) Saline sham injections → override both regions        #     Match anything that mentions both "saline" and "sham"        if "saline" in ttype and "sham" in ttype:            label = "sham saline injection"            entry["Medial Area X hit type"] = label            entry["Lateral Area X hit type"] = label            continue        # 2b) NMA lesions: if Area X not visible, override classification        is_nma_lesion = ("nma" in ttype) and ("lesion" in ttype)        if is_nma_lesion and ax_visible_flag is False:            # NMA lesion and Area X is not visible in histology            label = "large lesion, Area X not visible"            entry["Medial Area X hit type"] = label            entry["Lateral Area X hit type"] = label            continue        # 2c) Otherwise (including NMA lesions with visible/unknown visibility        #      and any other treatment types), fall back to the original        #      bilateral/unilateral/miss/unknown logic based on Y/N flags.        med_type = _classify_hit_type(            entry,            hit_key="Medial Area X hit?",            target_keyword="Medial Area X",        )        lat_type = _classify_hit_type(            entry,            hit_key="Lateral Area X hit?",            target_keyword="Lateral Area X",        )        entry["Medial Area X hit type"] = med_type        entry["Lateral Area X hit type"] = lat_type    return metadata"""Example usage (no graphing)---------------------------from pathlib import Pathfrom pprint import pprintimport pandas as pdfrom organize_metadata_excel import build_areax_metadata# Path to histology directory where your *_final_volumes.json livehistology_volumes_dir = Path(    "/Volumes/my_own_ssd/2024_2025_Area_X_analysis/lesion_quantification_csvs_jsons")# Path to your Excel sheetexcel_file = Path(    "/Volumes/my_own_ssd/2024_2025_Area_X_analysis/Area_X_lesion_metadata.xlsx")# Build the per-animal metadata dictionary, including lesion-volume JSONsmetadata = build_areax_metadata(    excel_file,    sheet_name=0,    volumes_dir=histology_volumes_dir,   # <-- new argument (optional))# Inspect one animal entry (replace "R10" with a real Animal ID from your sheet)pprint(metadata["R10"])# Convert the metadata dict into a DataFrame (one row per animal)organized_metadata = pd.DataFrame.from_dict(metadata, orient="index")# Check the available columns, including the derived fieldsprint(organized_metadata.columns)# Look at the first few rowsprint(organized_metadata.head())# Inspect the distribution of hit types:print("Medial Area X hit type categories:")print(organized_metadata["Medial Area X hit type"].value_counts(dropna=False))print("\\nLateral Area X hit type categories:")print(organized_metadata["Lateral Area X hit type"].value_counts(dropna=False))# And, for example, look at lesion percentages by hemisphere if present:print("\\nL Percent Area X lesioned:")print(organized_metadata["L_Percent_of_Area_X_Lesioned_pct"].dropna())print("\\nR Percent Area X lesioned:")print(organized_metadata["R_Percent_of_Area_X_Lesioned_pct"].dropna())"""